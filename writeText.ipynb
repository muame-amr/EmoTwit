{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCsv():\n",
    "  pos_df = pd.read_json(\"datasets/twitter-malaya/strong-positives.json\")\n",
    "  neg_df = pd.read_json(\"datasets/twitter-malaya/strong-negatives.json\")\n",
    "  pos_train_idx = int(np.floor(0.8 * 1084592))\n",
    "  neg_train_idx = int(np.floor(0.8 * 1892193))\n",
    "\n",
    "  # Shuffle the data\n",
    "  shuff_pos = pos_df.sample(frac=1)\n",
    "  shuff_neg = neg_df.sample(frac=1)\n",
    "\n",
    "  # Split the data\n",
    "  pos_train = shuff_pos[:pos_train_idx]\n",
    "  pos_test = shuff_pos[pos_train_idx:]\n",
    "  neg_train = shuff_neg[:neg_train_idx]\n",
    "  neg_test = shuff_neg[neg_train_idx:]\n",
    "\n",
    "  # Convert to txt/csv file\n",
    "  pos_train.to_csv(\"datasets/twitter-malaya/train/pos_train.csv\", index=False)\n",
    "  pos_test.to_csv(\"datasets/twitter-malaya/test/pos_test.csv\", index=False)\n",
    "  neg_train.to_csv(\"datasets/twitter-malaya/train/neg_train.csv\", index=False)\n",
    "  neg_test.to_csv(\"datasets/twitter-malaya/test/neg_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorToTxt():\n",
    "  data = np.load(\"datasets/word2vec-ms-socialmedia-256.npy\")\n",
    "  np.savetxt('datasets/word2vec-ms-socialmedia-256.txt', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragmentVectorToTxt():\n",
    "  data = np.load(\"datasets/word2vec-ms-socialmedia-256.npy\")\n",
    "  np.random.shuffle(data)\n",
    "  newData = data[:129463]\n",
    "  np.savetxt('datasets/fragmented-word2vec-ms-socialmedia-256.txt', newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text_positive():\n",
    "    with open(\"./datasets/twitter-malaya/strong-positives.json\") as f:\n",
    "        text_list = json.load(f)\n",
    "        for text in text_list:\n",
    "            print(text)\n",
    "        # filename = \"./datasets/strong-positives.txt\"\n",
    "        # with open(filename, 'w') as fileS:\n",
    "        #     for text in text_list:\n",
    "        #         file.write(text)\n",
    "        #         file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wirte_to_text_negative(idx):\n",
    "  with open(negative_list[idx]) as f:\n",
    "        text_list = json.load(f)\n",
    "        filename = \"./datasets/negative/\" + str(idx) + \".txt\"\n",
    "        with open(filename, 'w') as file:\n",
    "            for text in text_list:\n",
    "                file.write(text)\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  pos_df = pd.read_json(\"datasets/twitter-malaya/strong-positives.json\")\n",
    "  neg_df = pd.read_json(\"datasets/twitter-malaya/strong-negatives.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nasikebuli07 @FANBASEBOKEP2 Dom jakpus sih, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@seolasidooo Jujur kacang ijo !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahur tengah malam kaya nya enak ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Ini_Talkshow @tiket\\n\\nMakan serabi enak pas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@imtaeyonglee loh kenapa? kan marga oppa juga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976780</th>\n",
       "      <td>@abcd_leni Kau masih berharap dalam harap yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976781</th>\n",
       "      <td>Malam senin .. tidur cept ah. Biar gak terlmba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976782</th>\n",
       "      <td>Aku ilfeel sama cewe yang bisa main musik. Ane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976783</th>\n",
       "      <td>sekali aku tegur kau buat tak tau, jangan hara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976784</th>\n",
       "      <td>Tapi showroom tu boleh tolak ketepi buat masa ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2976785 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "0        @nasikebuli07 @FANBASEBOKEP2 Dom jakpus sih, b...\n",
       "1                        @seolasidooo Jujur kacang ijo !! \n",
       "2                  Sahur tengah malam kaya nya enak ya... \n",
       "3        @Ini_Talkshow @tiket\\n\\nMakan serabi enak pas ...\n",
       "4        @imtaeyonglee loh kenapa? kan marga oppa juga ...\n",
       "...                                                    ...\n",
       "2976780  @abcd_leni Kau masih berharap dalam harap yang...\n",
       "2976781  Malam senin .. tidur cept ah. Biar gak terlmba...\n",
       "2976782  Aku ilfeel sama cewe yang bisa main musik. Ane...\n",
       "2976783  sekali aku tegur kau buat tak tau, jangan hara...\n",
       "2976784  Tapi showroom tu boleh tolak ketepi buat masa ...\n",
       "\n",
       "[2976785 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2976785\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"./datasets/twitter-malaya/raw_tweets.txt\"\n",
    "with open(filename, 'w') as file:\n",
    "  for tweets in full_df.values:\n",
    "    file.write(''.join(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['@nasikebuli07 @FANBASEBOKEP2 Dom jakpus sih, bebas mau ketemuan or shopee'],\n",
       "       ['@seolasidooo Jujur kacang ijo !! '],\n",
       "       ['Sahur tengah malam kaya nya enak ya... '],\n",
       "       ...,\n",
       "       ['Aku ilfeel sama cewe yang bisa main musik. Aneh mang aku :)'],\n",
       "       ['sekali aku tegur kau buat tak tau, jangan harap aku balas teguran kau even once'],\n",
       "       ['Tapi showroom tu boleh tolak ketepi buat masa sekarang tetapi fabric raya guane sehhhh! Dari printed fabrics ke seg https://t.co/rDhSsNebPL']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aecd030d4c8316a52bf122072e28f84bcc79844c2684e041fef2e3f1d9f59078"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

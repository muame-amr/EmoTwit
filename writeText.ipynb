{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCsv():\n",
    "  pos_df = pd.read_json(\"datasets/twitter-malaya/strong-positives.json\")\n",
    "  neg_df = pd.read_json(\"datasets/twitter-malaya/strong-negatives.json\")\n",
    "  pos_train_idx = int(np.floor(0.8 * 1084592))\n",
    "  neg_train_idx = int(np.floor(0.8 * 1892193))\n",
    "\n",
    "  # Shuffle the data\n",
    "  shuff_pos = pos_df.sample(frac=1)\n",
    "  shuff_neg = neg_df.sample(frac=1)\n",
    "\n",
    "  # Split the data\n",
    "  pos_train = shuff_pos[:pos_train_idx]\n",
    "  pos_test = shuff_pos[pos_train_idx:]\n",
    "  neg_train = shuff_neg[:neg_train_idx]\n",
    "  neg_test = shuff_neg[neg_train_idx:]\n",
    "\n",
    "  # Convert to txt/csv file\n",
    "  pos_train.to_csv(\"datasets/twitter-malaya/train/pos_train.txt\", index=False)\n",
    "  pos_test.to_csv(\"datasets/twitter-malaya/test/pos_test.txt\", index=False)\n",
    "  neg_train.to_csv(\"datasets/twitter-malaya/train/neg_train.txt\", index=False)\n",
    "  neg_test.to_csv(\"datasets/twitter-malaya/test/neg_test.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorToTxt():\n",
    "  data = np.load(\"datasets/word2vec-ms-socialmedia-256.npy\")\n",
    "  np.savetxt('datasets/word2vec-ms-socialmedia-256.txt', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragmentVectorToTxt():\n",
    "  data = np.load(\"datasets/word2vec-ms-socialmedia-256.npy\")\n",
    "  np.random.shuffle(data)\n",
    "  newData = data[:129463]\n",
    "  np.savetxt('datasets/fragmented-word2vec-ms-socialmedia-256.txt', newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text_positive():\n",
    "    with open(\"./datasets/twitter-malaya/strong-positives.json\") as f:\n",
    "        text_list = json.load(f)\n",
    "        for text in text_list:\n",
    "            print(text)\n",
    "        # filename = \"./datasets/strong-positives.txt\"\n",
    "        # with open(filename, 'w') as fileS:\n",
    "        #     for text in text_list:\n",
    "        #         file.write(text)\n",
    "        #         file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wirte_to_text_negative(idx):\n",
    "  with open(negative_list[idx]) as f:\n",
    "        text_list = json.load(f)\n",
    "        filename = \"./datasets/negative/\" + str(idx) + \".txt\"\n",
    "        with open(filename, 'w') as file:\n",
    "            for text in text_list:\n",
    "                file.write(text)\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text_malaya():\n",
    "  pos_df = pd.read_json(\"datasets/twitter-malaya/strong-positives.json\")\n",
    "  neg_df = pd.read_json(\"datasets/twitter-malaya/strong-negatives.json\")\n",
    "  full_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "  filename = \"./datasets/twitter-malaya/raw_tweets.txt\"\n",
    "  with open(filename, 'w') as file:\n",
    "    for tweets in full_df.values:\n",
    "      file.write(''.join(tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_csv(\"datasets/twitter-malaya-clean/train/pos_train.txt\", header=None)\n",
    "neg_df = pd.read_csv(\"datasets/twitter-malaya-clean/train/neg_train.txt\", header=None)\n",
    "pos_test = pd.read_csv(\"datasets/twitter-malaya-clean/test/pos_test.txt\", header=None)\n",
    "neg_test = pd.read_csv(\"datasets/twitter-malaya-clean/test/neg_test.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff_pos = pos_df.sample(frac=1)\n",
    "shuff_neg = neg_df.sample(frac=1)\n",
    "shuff_tpos = pos_test.sample(frac=1)\n",
    "shuff_tneg = neg_test.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = shuff_pos[:125000]\n",
    "final_neg = shuff_neg[:125000]\n",
    "final_tpos = shuff_tpos[:5000]\n",
    "final_tneg = shuff_tneg[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_pos.shape)\n",
    "print(final_neg.shape)\n",
    "print(final_tpos.shape)\n",
    "print(final_tneg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos.to_csv(\"datasets/twitter-malaya/train/pos_train.txt\", index=False)\n",
    "final_tpos.to_csv(\"datasets/twitter-malaya/test/pos_test.txt\", index=False)\n",
    "final_neg.to_csv(\"datasets/twitter-malaya/train/neg_train.txt\", index=False)\n",
    "final_tneg.to_csv(\"datasets/twitter-malaya/test/neg_test.txt\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aecd030d4c8316a52bf122072e28f84bcc79844c2684e041fef2e3f1d9f59078"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
